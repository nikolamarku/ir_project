{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d1ec8f-5eda-4842-98a0-1eadd1d5a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd791daa-4ee5-4189-8211-e2bc5c49a09f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('arxiv.csv')\n",
    "abstracts = df['abstracts'][:40000].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c010f203-c238-4dfc-94be-78088be854f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import string\n",
    "import unicodedata\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788c276-a7cc-4c70-83ad-12f728305651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def remove_numbers(str):\n",
    "#    return re.sub(r\"\\d*|\\d*\\.\\d+|\\d*\\,\\d+\", '', str)\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def clean_text(text):\n",
    "    return unicodeToAscii(re.sub(r\"”|“\",'\"',text).replace(\"’\",\"'\"))\n",
    "\n",
    "\n",
    "def build_structure(input):\n",
    "    acc = []\n",
    "    stack = []\n",
    "    for token in input:\n",
    "        if token == \"'s\":\n",
    "            acc = acc[:-1] + [(acc[-1] + token) if len(acc) > 0 else token]\n",
    "        elif token in (list(string.punctuation) + [\"''\",\"``\",\"’\"]):\n",
    "            stack += [(' '.join(acc),token + ' ')]\n",
    "            acc = []\n",
    "        else:\n",
    "            acc += [token]\n",
    "    stack += [(' '.join(acc),None)]\n",
    "    res = None\n",
    "    for x in stack[::-1]:\n",
    "        res = (x[0],x[1],res)\n",
    "    return res\n",
    "\n",
    "\n",
    "def structure_to_sentences(structure):\n",
    "    res = []\n",
    "    next = structure\n",
    "    while next is not None:\n",
    "        str, sep, next = next\n",
    "        if len(str) > 0:\n",
    "            res += [str]\n",
    "    return res\n",
    "\n",
    "def transf(s):\n",
    "    return structure_to_sentences(build_structure(word_tokenize(clean_text(s))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015dbe0-c453-4dfb-a5bf-8c9f51f5f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_sentences = []\n",
    "for abstract in abstracts:\n",
    "    sentences = transf(abstract)\n",
    "    for sentence in sentences:\n",
    "        abstract_sentences += [sentence]\n",
    "len(abstract_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73f8df-3a46-4537-b163-541dd0d27e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'sentence':abstract_sentences})\n",
    "df = df.drop_duplicates(subset=['sentence'])\n",
    "df = df[df['sentence'].apply(lambda x: len(x.split(' '))) > 1]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6d983b-33f9-4640-bf7a-059a54c35ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 200\n",
    "def max_x_chars(max_len):\n",
    "    def truncate_sentence(str):\n",
    "        splitted_str = str.split(\" \")\n",
    "        word_lengths = [len(w) for w in splitted_str]\n",
    "        cum_sum = np.cumsum(word_lengths)\n",
    "        end = [i for i,x in enumerate(cum_sum) if x <= max_len][-1]\n",
    "        return ' '.join(splitted_str[:end+1])\n",
    "    return truncate_sentence\n",
    "\n",
    "truncate = max_x_chars(SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad117eea-53f0-4b34-89df-09124ce25ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sentence'].apply(lambda o: type(o) is str)]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309f7e29-0454-4e72-9fe3-f28870a22d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['original'] = df['sentence']\n",
    "\n",
    "# expected output. 'hello world' become 'h e l l o # w o r l d'\n",
    "df['expected'] = df['sentence'].apply(lambda x: ' ## '.join([' '.join(w) for w in x.split(' ')]))\n",
    "\n",
    "# input. 'hello world' become 'h e l l o w o r l d'\n",
    "df['sentence'] = df['sentence'].apply(lambda x: ' '.join([' '.join(w) for w in x.split(' ')]))\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef65f4-1337-4f1b-b1c2-14b7aacc5fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of string saved to file\n",
    "def list_to_file(list, filename):\n",
    "    with open(filename, 'w') as fp:\n",
    "        for el in list:\n",
    "            fp.write(f\"{el}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c573e4f-1382-4dfb-b441-9eb95f798283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_files(split, name):\n",
    "    list_to_file([s for s,_ in split], f\"./{name}-source.txt\")\n",
    "    list_to_file([t for _,t in split], f\"./{name}-target.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d311ac-aabd-4beb-81e8-27406fc4e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {\n",
    "    'abstract' : [(source,target) for (source,target) in zip(df['sentence'],df['expected'])],\n",
    "}\n",
    "for k,v in splits.items():\n",
    "    split_to_files(v,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf53e3ce-b9f8-4b40-b290-25877e969ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!onmt_translate -model final_model.pt -src abstract-source.txt -output abstract-translation.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d27cc60-26f4-4f5f-95d5-40ece790c2f8",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab04c68-5129-424d-91c7-d58057bf22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"abstract-target.txt\",\"r\")\n",
    "test_l = f.read().split(\"\\n\")\n",
    "f.close()\n",
    "f = open(\"abstract-translation.txt\",\"r\")\n",
    "predicted_l = f.read().split(\"\\n\")\n",
    "f.close()\n",
    "len(test_l), len(predicted_l)\n",
    "test_l = test_l[:-1]\n",
    "predicted_l = predicted_l[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d796e5d-42ab-4037-9967-de26ede52a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_l = [(pred,test) for pred,test in zip(predicted_l,test_l) if len(test.split('##')) > 1]\n",
    "predicted_l = [pred.replace(' ','').replace('##',' ') for pred,_ in pair_l]\n",
    "test_l = [test.replace(' ','').replace('##',' ') for _,test in pair_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a82a0d55-fba3-453c-ac48-e4b42f8652a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(pred,gt):\n",
    "    words_pred = set(pred.split(' '))\n",
    "    words_gt = set(gt.split(' '))\n",
    "    return len(set.intersection(words_pred,words_gt)) / len(pred.split(' '))\n",
    "P = (sum([precision(pred,test) for (pred,test) in zip(predicted_l,test_l)])/len(test_l)) * 100\n",
    "\n",
    "def recall(pred,gt):\n",
    "    words_pred = set(pred.split(' '))\n",
    "    words_gt = set(gt.split(' '))\n",
    "    return len(set.intersection(words_pred,words_gt)) / len(gt.split(' '))\n",
    "    \n",
    "R = (sum([recall(pred,test) for (pred,test) in zip(predicted_l,test_l)])/len(test_l)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f76c153c-147b-4f18-be45-eea27ab1db01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91.09577509093276, 91.82453869385112, 91.45870517722169)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P,R,2/((1/P) + (1/R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46f9fbd5-7f51-4010-aa0f-308e89d50716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07911392351871394"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jiwer import wer\n",
    "import numpy as np\n",
    "wers = [wer(test, pred) for pred,test in zip(predicted_l, test_l)]\n",
    "sum(wers)/len(predicted_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92a2e0cb-f583-4e20-8036-72f341e9477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'sl': [len(x.split(' ')) for x in test_l], 'wer':wers})\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baaacee4-c23d-4c72-be37-c39ea4952a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('plots/abstracts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
